# Vision AI Video Moderation Pipeline

Automated video content moderation system using YOLO, RAM, and BLIP models to detect violent or inappropriate content.

## ðŸš€ Quick Start

### Step 1: Clone Repository
```bash
git clone https://github.com/Akhil4007-cpu/RAYV-content-moderation.git
cd RAYV-content-moderation
```

### Step 2: Create Virtual Environment
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Download RAM Model Checkpoint
1. Download `ram_swin_large_14m.pth` from:
   - [HuggingFace](https://huggingface.co/spaces/xinyu1205/recognize-anything)
2. Create `checkpoints` folder and place file:
   ```bash
   mkdir checkpoints
   # Move ram_swin_large_14m.pth to checkpoints/
   ```

### Step 5: Run Pipeline
```bash
python main_pipeline.py --video your_video.mp4
```

**That's it!** Results will be saved in `outputs/[video_name_timestamp]/`

---

## ðŸ“– Detailed Step-by-Step Guide

### Installation

#### Prerequisites
- Python 3.8 or higher
- CUDA-capable GPU (optional, CPU works but slower)
- 8GB+ RAM
- 5GB+ free disk space

#### Complete Installation Steps

1. **Navigate to project directory**
   ```bash
   cd vision_ai_clean
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   ```

3. **Activate virtual environment**
   ```bash
   # Windows
   venv\Scripts\activate
   
   # Linux/Mac
   source venv/bin/activate
   ```

4. **Upgrade pip**
   ```bash
   pip install --upgrade pip
   ```

5. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

6. **Download RAM checkpoint**
   - Visit: https://huggingface.co/spaces/xinyu1205/recognize-anything
   - Download `ram_swin_large_14m.pth`
   - Create `checkpoints` folder: `mkdir checkpoints`
   - Place file: `checkpoints/ram_swin_large_14m.pth`

7. **Verify installation**
   - YOLO model auto-downloads on first run
   - BLIP/CLIP models auto-download from HuggingFace

### Usage

#### Basic Usage
```bash
python main_pipeline.py --video input_video.mp4
```

#### What Happens Automatically:
1. âœ… **Outputs folder is cleaned** - Previous results removed
2. âœ… **New session created** - `outputs/video_name_timestamp/`
3. âœ… **Frames extracted** - From video at regular intervals
4. âœ… **Duplicates removed** - Using CLIP embeddings
5. âœ… **Windows created** - Temporal analysis groups
6. âœ… **Multimodal analysis** - YOLO + RAM + BLIP
7. âœ… **Risk assessment** - Advanced scoring system
8. âœ… **Final decision** - SAFE/RISKY/VIOLENT classification

#### Advanced Options
```bash
# Keep previous results (don't clean outputs)
python main_pipeline.py --video input.mp4 --keep-results

# Custom output directory
python main_pipeline.py --video input.mp4 --output-dir outputs/my_custom_folder

# Run specific steps only
python main_pipeline.py --video input.mp4 --step extract --step analyze

# Skip dependency checks
python main_pipeline.py --video input.mp4 --no-checks
```

### Output Structure

After running, check `outputs/[video_name_timestamp]/`:

```
outputs/
â””â”€â”€ video_name_20260110_163906/
    â”œâ”€â”€ frames_raw/              # All extracted frames
    â”œâ”€â”€ frames_unique/           # Deduplicated frames
    â”œâ”€â”€ window_results.json      # Per-window analysis
    â”œâ”€â”€ windows_info.json        # Window structure
    â””â”€â”€ final_moderation_result.json  # Final decision
```

### Understanding Results

#### Final Result JSON
```json
{
  "final_label": "SAFE",
  "confidence": 0.95,
  "risk_score": 0.15,
  "reason": "Low risk across all windows",
  "statistics": {
    "total_windows": 10,
    "safe_windows": 10,
    "risky_windows": 0,
    "violent_windows": 0
  }
}
```

**Labels:**
- `SAFE` - No concerning content detected
- `RISKY` - Some concerning elements, review recommended
- `VIOLENT` - Clear violent/inappropriate content detected

### Configuration

Edit `config.py` to customize:
- **Device**: CPU/GPU selection
- **Model paths**: Custom model locations
- **Risk thresholds**: Sensitivity adjustments
- **Window size**: Temporal analysis granularity
- **Batch size**: Processing speed vs memory

### Troubleshooting

**Problem**: Import errors
- **Solution**: Activate virtual environment: `venv\Scripts\activate`

**Problem**: RAM model not found
- **Solution**: Download `ram_swin_large_14m.pth` to `checkpoints/`

**Problem**: Out of memory
- **Solution**: Reduce `BATCH_SIZE` in `config.py` or use CPU

**Problem**: Slow processing
- **Solution**: Use GPU (CUDA) - set `DEVICE = "cuda"` in `config.py`

**Problem**: Previous results not cleaned
- **Solution**: Results auto-clean on each run. Use `--keep-results` to preserve.

---

## ðŸ—ï¸ Project Structure

### Core Files
- `main_pipeline.py` - **Main entry point** (run this!)
- `config.py` - All configuration settings
- `model_manager.py` - Shared model loading (no duplication)
- `risk_scorer.py` - Risk assessment logic
- `action_recognition.py` - Action pattern detection

### Pipeline Steps
- `step7a_extract_frames.py` - Extract frames from video
- `step7b_remove_duplicates.py` - Remove duplicate frames (CLIP)
- `step7c_build_windows.py` - Create temporal windows
- `step7d_window_multimodal_analysis.py` - Analyze with YOLO/RAM/BLIP
- `step8_video_decision_engine.py` - Final moderation decision

---

## ðŸ”¬ How It Works

1. **Frame Extraction** - Extracts frames at regular intervals (0.5s default)
2. **Deduplication** - Removes similar frames using CLIP embeddings (97% similarity threshold)
3. **Window Creation** - Groups frames into temporal windows (5 frames per window)
4. **Multimodal Analysis** - Each window analyzed with:
   - **YOLO**: Object detection (weapons, persons, vehicles)
   - **RAM**: Scene tagging (context understanding - kitchen, street, etc.)
   - **BLIP**: Image captioning (descriptive text)
5. **Risk Assessment** - Calculates risk score using:
   - Weapon detection
   - Motion analysis (optical flow)
   - Action recognition (fighting, attacking)
   - Context awareness (safe contexts reduce risk)
6. **Decision** - Final SAFE/RISKY/VIOLENT classification

---

## ðŸŽ¯ Features

- âœ… **Multi-model ensemble** (YOLO + RAM + BLIP)
- âœ… **Temporal analysis** (sliding windows)
- âœ… **Context-aware** risk scoring
- âœ… **Weapon detection** (knife, baseball bat, scissors)
- âœ… **Motion detection** (optical flow)
- âœ… **Action recognition** (fighting, attacking)
- âœ… **Model caching** (fast execution)
- âœ… **Auto-clean outputs** (fresh results every run)
- âœ… **Session management** (organized outputs)

---

## ðŸ“¦ Requirements

- Python 3.8+
- PyTorch
- CUDA GPU (optional, CPU works but slower)
- 8GB+ RAM
- 5GB+ disk space

---

## ðŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -m "Add feature"`
4. Push to branch: `git push origin feature-name`
5. Submit pull request

---

## ðŸ“„ License

See individual model licenses:
- YOLO: AGPL-3.0
- RAM: Apache 2.0
- BLIP: BSD-3-Clause

---

## ðŸ”— GitHub Hosting Guide

### Step 1: Create GitHub Repository
1. Go to https://github.com/new
2. Repository name: `vision_ai_clean`
3. Description: "AI-powered video content moderation pipeline"
4. Choose Public or Private
5. **Don't** initialize with README (we already have one)
6. Click "Create repository"

### Step 2: Initialize Git (if not already)
```bash
git init
```

### Step 3: Create .gitignore
```bash
# Create .gitignore file
cat > .gitignore << EOF
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
env/
ENV/

# Models and checkpoints
*.pt
*.pth
checkpoints/
yolov8n.pt

# Outputs
outputs/
frames_raw/
frames_unique/
*.json

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Large files
*.mp4
*.avi
*.mov
*.mkv
EOF
```

### Step 4: Add and Commit Files
```bash
git add .
git commit -m "Initial commit: Vision AI Video Moderation Pipeline"
```

### Step 5: Connect to GitHub
```bash
git remote add origin https://github.com/yourusername/vision_ai_clean.git
git branch -M main
git push -u origin main
```

### Step 6: Add Repository Topics (Optional)
On GitHub, click "Add topics" and add:
- `computer-vision`
- `video-moderation`
- `yolo`
- `deep-learning`
- `ai`
- `content-moderation`

### Step 7: Update README with Your GitHub Link
Replace `yourusername` in the clone command above with your actual GitHub username.

---

## ðŸ“± LinkedIn Post Template

### Option 1: Technical Focus
```
ðŸš€ Excited to share my latest project: Vision AI Video Moderation Pipeline!

A comprehensive AI-powered system that automatically detects violent or inappropriate content in videos using state-of-the-art computer vision models.

ðŸ”§ Tech Stack:
â€¢ YOLO v8 - Object detection
â€¢ RAM (Recognize Anything Model) - Scene understanding
â€¢ BLIP - Image captioning
â€¢ CLIP - Duplicate frame removal
â€¢ PyTorch - Deep learning framework

âœ¨ Key Features:
âœ… Multi-model ensemble for robust detection
âœ… Temporal analysis with sliding windows
âœ… Context-aware risk scoring
âœ… Weapon detection (knives, bats, etc.)
âœ… Motion analysis using optical flow
âœ… Action recognition (fighting, attacking)

The pipeline processes videos through multiple stages:
1. Frame extraction & deduplication
2. Temporal window grouping
3. Multimodal analysis (YOLO + RAM + BLIP)
4. Advanced risk assessment
5. Final moderation decision

Perfect for content platforms, social media moderation, or safety applications.

ðŸ”— Check it out: [GitHub Link]
ðŸ’» Built with Python, PyTorch, and modern CV techniques

#AI #ComputerVision #DeepLearning #VideoModeration #YOLO #PyTorch #MachineLearning #OpenSource
```

### Option 2: Problem-Solution Focus
```
ðŸŽ¯ Problem: How do you automatically moderate video content at scale?

ðŸ’¡ Solution: Vision AI Video Moderation Pipeline

I built an AI system that combines multiple state-of-the-art models to automatically detect and classify potentially violent or inappropriate content in videos.

The system uses:
â€¢ Object detection to identify weapons and people
â€¢ Scene understanding to recognize context
â€¢ Image captioning for descriptive analysis
â€¢ Temporal analysis to understand actions over time

Result: Automated, accurate, and scalable video moderation.

ðŸ”— GitHub: [Your Link]
ðŸ“Š Features: Multi-model ensemble, context-aware scoring, real-time processing

#AI #VideoModeration #ComputerVision #DeepLearning #OpenSource
```

### Option 3: Achievement Focus
```
ðŸŽ‰ Just completed my Vision AI Video Moderation Pipeline!

After weeks of development, I've built a comprehensive system that:
âœ… Detects weapons and violent actions
âœ… Understands scene context (kitchen vs street)
âœ… Analyzes temporal patterns
âœ… Provides confidence-scored decisions

Built with YOLO, RAM, BLIP, and CLIP models - combining the best of object detection, scene understanding, and natural language processing.

Open source and ready for deployment! ðŸ”— [GitHub Link]

#AI #ComputerVision #MachineLearning #OpenSource #DeepLearning
```

### Option 4: Short & Impactful
```
ðŸš€ New Project: AI-Powered Video Moderation

Combining YOLO, RAM, and BLIP models to automatically detect violent/inappropriate content in videos.

âœ… Multi-model ensemble
âœ… Context-aware analysis
âœ… Temporal understanding
âœ… Open source

Perfect for content platforms and safety applications.

ðŸ”— [GitHub Link]

#AI #ComputerVision #VideoModeration #OpenSource
```

---

## ðŸ“§ Support

For issues or questions:
- Open an issue on GitHub
- Check existing issues for solutions
- Review the troubleshooting section above

---

**Made with â¤ï¸ for automated content moderation**
